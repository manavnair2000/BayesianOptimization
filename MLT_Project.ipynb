{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLT Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNRegZpfyg9bUOdQS15GfGh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manavnair2000/BayesianOptimization/blob/master/MLT_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-wpKwZP2b05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# objective function\n",
        "def objective(x, noise=0.1):\n",
        "\tnoise = normal(loc=0, scale=noise)\n",
        "\treturn (x**2 * sin(5 * pi * x)**6.0) + noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9MJTOFu2wWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        "# grid-based sample of the domain [0,1]\n",
        "X = arange(0, 1, 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3TlR4m63MVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        "# sample the domain without noise\n",
        "y = [objective(x, 0) for x in X]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afJOZp3K3O2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        "# sample the domain with noise\n",
        "ynoise = [objective(x) for x in X]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULXCXzxD3R5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        "# sample the domain with noise\n",
        "ynoise = [objective(x) for x in X]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqsA7BJv3Tuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        "# plot the points with noise\n",
        "pyplot.scatter(X, ynoise)\n",
        "# plot the points without noise\n",
        "pyplot.plot(X, y)\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JgJnB363V-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of the test problem\n",
        "from math import sin\n",
        "from math import pi\n",
        "from numpy import arange\n",
        "from numpy import argmax\n",
        "from numpy.random import normal\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# objective function\n",
        "def objective(x, noise=0.1):\n",
        "\tnoise = normal(loc=0, scale=noise)\n",
        "\treturn (x**2 * sin(5 * pi * x)**6.0) + noise\n",
        "\n",
        "# grid-based sample of the domain [0,1]\n",
        "X = arange(0, 1, 0.01)\n",
        "# sample the domain without noise\n",
        "y = [objective(x, 0) for x in X]\n",
        "# sample the domain with noise\n",
        "ynoise = [objective(x) for x in X]\n",
        "# find best result\n",
        "ix = argmax(y)\n",
        "print('Optima: x=%.3f, y=%.3f' % (X[ix], y[ix]))\n",
        "# plot the points with noise\n",
        "pyplot.scatter(X, ynoise)\n",
        "# plot the points without noise\n",
        "pyplot.plot(X, y)\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R4SMZBS3cCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Optima: x=0.900, y=0.810"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISF_7VW234c0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        "# define the model\n",
        "model = GaussianProcessRegressor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlgQOTm13-UH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        "# fit the model\n",
        "model.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lck39Cq4NdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        "yhat = model.predict(X, return_std=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKn47Fxw4d8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# surrogate or approximation for the objective function\n",
        "def surrogate(model, X):\n",
        "\t# catch any warning generated when making a prediction\n",
        "\twith catch_warnings():\n",
        "\t\t# ignore generated warnings\n",
        "\t\tsimplefilter(\"ignore\")\n",
        "\t\treturn model.predict(X, return_std=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS5Pfjuz4gMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot real observations vs surrogate function\n",
        "def plot(X, y, model):\n",
        "\t# scatter plot of inputs and real objective function\n",
        "\tpyplot.scatter(X, y)\n",
        "\t# line plot of surrogate function across domain\n",
        "\tXsamples = asarray(arange(0, 1, 0.001))\n",
        "\tXsamples = Xsamples.reshape(len(Xsamples), 1)\n",
        "\tysamples, _ = surrogate(model, Xsamples)\n",
        "\tpyplot.plot(Xsamples, ysamples)\n",
        "\t# show the plot\n",
        "\tpyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtmR0TeK4iew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of a gaussian process surrogate function\n",
        "from math import sin\n",
        "from math import pi\n",
        "from numpy import arange\n",
        "from numpy import asarray\n",
        "from numpy.random import normal\n",
        "from numpy.random import random\n",
        "from matplotlib import pyplot\n",
        "from warnings import catch_warnings\n",
        "from warnings import simplefilter\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "\n",
        "# objective function\n",
        "def objective(x, noise=0.1):\n",
        "\tnoise = normal(loc=0, scale=noise)\n",
        "\treturn (x**2 * sin(5 * pi * x)**6.0) + noise\n",
        "\n",
        "# surrogate or approximation for the objective function\n",
        "def surrogate(model, X):\n",
        "\t# catch any warning generated when making a prediction\n",
        "\twith catch_warnings():\n",
        "\t\t# ignore generated warnings\n",
        "\t\tsimplefilter(\"ignore\")\n",
        "\t\treturn model.predict(X, return_std=True)\n",
        "\n",
        "# plot real observations vs surrogate function\n",
        "def plot(X, y, model):\n",
        "\t# scatter plot of inputs and real objective function\n",
        "\tpyplot.scatter(X, y)\n",
        "\t# line plot of surrogate function across domain\n",
        "\tXsamples = asarray(arange(0, 1, 0.001))\n",
        "\tXsamples = Xsamples.reshape(len(Xsamples), 1)\n",
        "\tysamples, _ = surrogate(model, Xsamples)\n",
        "\tpyplot.plot(Xsamples, ysamples)\n",
        "\t# show the plot\n",
        "\tpyplot.show()\n",
        "\n",
        "# sample the domain sparsely with noise\n",
        "X = random(100)\n",
        "y = asarray([objective(x) for x in X])\n",
        "# reshape into rows and cols\n",
        "X = X.reshape(len(X), 1)\n",
        "y = y.reshape(len(y), 1)\n",
        "# define the model\n",
        "model = GaussianProcessRegressor()\n",
        "# fit the model\n",
        "model.fit(X, y)\n",
        "# plot the surrogate function\n",
        "plot(X, y, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOr5rr2j4lr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimize the acquisition function\n",
        "def opt_acquisition(X, y, model):\n",
        "\t# random search, generate random samples\n",
        "\tXsamples = random(100)\n",
        "\tXsamples = Xsamples.reshape(len(Xsamples), 1)\n",
        "\t# calculate the acquisition function for each sample\n",
        "\tscores = acquisition(X, Xsamples, model)\n",
        "\t# locate the index of the largest scores\n",
        "\tix = argmax(scores)\n",
        "\treturn Xsamples[ix, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zfZ-fRp4n_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# probability of improvement acquisition function\n",
        "def acquisition(X, Xsamples, model):\n",
        "\t# calculate the best surrogate score found so far\n",
        "\tyhat, _ = surrogate(model, X)\n",
        "\tbest = max(yhat)\n",
        "\t# calculate mean and stdev via surrogate function\n",
        "\tmu, std = surrogate(model, Xsamples)\n",
        "\tmu = mu[:, 0]\n",
        "\t# calculate the probability of improvement\n",
        "\tprobs = norm.cdf((mu - best) / (std+1E-9))\n",
        "\treturn probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGcERmsi4sa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        "# perform the optimization process\n",
        "for i in range(100):\n",
        "\t# select the next point to sample\n",
        "\tx = opt_acquisition(X, y, model)\n",
        "\t# sample the point\n",
        "\tactual = objective(x)\n",
        "\t# summarize the finding for our own reporting\n",
        "\test, _ = surrogate(model, [[x]])\n",
        "\tprint('>x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n",
        "\t# add the data to the dataset\n",
        "\tX = vstack((X, [[x]]))\n",
        "\ty = vstack((y, [[actual]]))\n",
        "\t# update the model\n",
        "\tmodel.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcwTCs7h4ueT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of bayesian optimization for a 1d function from scratch\n",
        "from math import sin\n",
        "from math import pi\n",
        "from numpy import arange\n",
        "from numpy import vstack\n",
        "from numpy import argmax\n",
        "from numpy import asarray\n",
        "from numpy.random import normal\n",
        "from numpy.random import random\n",
        "from scipy.stats import norm\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from warnings import catch_warnings\n",
        "from warnings import simplefilter\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# objective function\n",
        "def objective(x, noise=0.1):\n",
        "\tnoise = normal(loc=0, scale=noise)\n",
        "\treturn (x**2 * sin(5 * pi * x)**6.0) + noise\n",
        "\n",
        "# surrogate or approximation for the objective function\n",
        "def surrogate(model, X):\n",
        "\t# catch any warning generated when making a prediction\n",
        "\twith catch_warnings():\n",
        "\t\t# ignore generated warnings\n",
        "\t\tsimplefilter(\"ignore\")\n",
        "\t\treturn model.predict(X, return_std=True)\n",
        "\n",
        "# probability of improvement acquisition function\n",
        "def acquisition(X, Xsamples, model):\n",
        "\t# calculate the best surrogate score found so far\n",
        "\tyhat, _ = surrogate(model, X)\n",
        "\tbest = max(yhat)\n",
        "\t# calculate mean and stdev via surrogate function\n",
        "\tmu, std = surrogate(model, Xsamples)\n",
        "\tmu = mu[:, 0]\n",
        "\t# calculate the probability of improvement\n",
        "\tprobs = norm.cdf((mu - best) / (std+1E-9))\n",
        "\treturn probs\n",
        "\n",
        "# optimize the acquisition function\n",
        "def opt_acquisition(X, y, model):\n",
        "\t# random search, generate random samples\n",
        "\tXsamples = random(100)\n",
        "\tXsamples = Xsamples.reshape(len(Xsamples), 1)\n",
        "\t# calculate the acquisition function for each sample\n",
        "\tscores = acquisition(X, Xsamples, model)\n",
        "\t# locate the index of the largest scores\n",
        "\tix = argmax(scores)\n",
        "\treturn Xsamples[ix, 0]\n",
        "\n",
        "# plot real observations vs surrogate function\n",
        "def plot(X, y, model):\n",
        "\t# scatter plot of inputs and real objective function\n",
        "\tpyplot.scatter(X, y)\n",
        "\t# line plot of surrogate function across domain\n",
        "\tXsamples = asarray(arange(0, 1, 0.001))\n",
        "\tXsamples = Xsamples.reshape(len(Xsamples), 1)\n",
        "\tysamples, _ = surrogate(model, Xsamples)\n",
        "\tpyplot.plot(Xsamples, ysamples)\n",
        "\t# show the plot\n",
        "\tpyplot.show()\n",
        "\n",
        "# sample the domain sparsely with noise\n",
        "X = random(100)\n",
        "y = asarray([objective(x) for x in X])\n",
        "# reshape into rows and cols\n",
        "X = X.reshape(len(X), 1)\n",
        "y = y.reshape(len(y), 1)\n",
        "# define the model\n",
        "model = GaussianProcessRegressor()\n",
        "# fit the model\n",
        "model.fit(X, y)\n",
        "# plot before hand\n",
        "plot(X, y, model)\n",
        "# perform the optimization process\n",
        "for i in range(100):\n",
        "\t# select the next point to sample\n",
        "\tx = opt_acquisition(X, y, model)\n",
        "\t# sample the point\n",
        "\tactual = objective(x)\n",
        "\t# summarize the finding\n",
        "\test, _ = surrogate(model, [[x]])\n",
        "\tprint('>x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n",
        "\t# add the data to the dataset\n",
        "\tX = vstack((X, [[x]]))\n",
        "\ty = vstack((y, [[actual]]))\n",
        "\t# update the model\n",
        "\tmodel.fit(X, y)\n",
        "\n",
        "# plot all samples and the final surrogate function\n",
        "plot(X, y, model)\n",
        "# best result\n",
        "ix = argmax(y)\n",
        "print('Best Result: x=%.3f, y=%.3f' % (X[ix], y[ix]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6krKzW1y4xWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        ">x=0.922, f()=0.661501, actual=0.682\n",
        ">x=0.895, f()=0.661668, actual=0.905\n",
        ">x=0.928, f()=0.648008, actual=0.403\n",
        ">x=0.908, f()=0.674864, actual=0.750\n",
        ">x=0.436, f()=0.071377, actual=-0.115"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKeJIDxc5CAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Best Result: x=0.905, y=1.150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rognlC3I5Czo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sudo pip install scikit-optimize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O19F-viw5HIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        "# generate 2d classification dataset\n",
        "X, y = make_blobs(n_samples=500, centers=3, n_features=2)\n",
        "# define the model\n",
        "model = KNeighborsClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lU43NGC5JYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        "# define the space of hyperparameters to search\n",
        "search_space = [Integer(1, 5, name='n_neighbors'), Integer(1, 2, name='p')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOAFwi3Y5KBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the function used to evaluate a given configuration\n",
        "@use_named_args(search_space)\n",
        "def evaluate_model(**params):\n",
        "\t# something\n",
        "\tmodel.set_params(**params)\n",
        "\t# calculate 5-fold cross validation\n",
        "\tresult = cross_val_score(model, X, y, cv=5, n_jobs=-1, scoring='accuracy')\n",
        "\t# calculate the mean of the scores\n",
        "\testimate = mean(result)\n",
        "\treturn 1.0 - estimate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpvBvRgJ5L3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        "# perform optimization\n",
        "result = gp_minimize(evaluate_model, search_space)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN8dBotR5Nz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        "# summarizing finding:\n",
        "print('Best Accuracy: %.3f' % (1.0 - result.fun))\n",
        "print('Best Parameters: n_neighbors=%d, p=%d' % (result.x[0], result.x[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv2fjhYD5PfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of bayesian optimization with scikit-optimize\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from skopt.space import Integer\n",
        "from skopt.utils import use_named_args\n",
        "from skopt import gp_minimize\n",
        "\n",
        "# generate 2d classification dataset\n",
        "X, y = make_blobs(n_samples=500, centers=3, n_features=2)\n",
        "# define the model\n",
        "model = KNeighborsClassifier()\n",
        "# define the space of hyperparameters to search\n",
        "search_space = [Integer(1, 5, name='n_neighbors'), Integer(1, 2, name='p')]\n",
        "\n",
        "# define the function used to evaluate a given configuration\n",
        "@use_named_args(search_space)\n",
        "def evaluate_model(**params):\n",
        "\t# something\n",
        "\tmodel.set_params(**params)\n",
        "\t# calculate 5-fold cross validation\n",
        "\tresult = cross_val_score(model, X, y, cv=5, n_jobs=-1, scoring='accuracy')\n",
        "\t# calculate the mean of the scores\n",
        "\testimate = mean(result)\n",
        "\treturn 1.0 - estimate\n",
        "\n",
        "# perform optimization\n",
        "result = gp_minimize(evaluate_model, search_space)\n",
        "# summarizing finding:\n",
        "print('Best Accuracy: %.3f' % (1.0 - result.fun))\n",
        "print('Best Parameters: n_neighbors=%d, p=%d' % (result.x[0], result.x[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "426rlPZ-5aPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UserWarning: The objective has been evaluated at this point before."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tqSE_9G5ezS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Best Accuracy: 0.976\n",
        "Best Parameters: n_neighbors=3, p=2"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}